<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title>Professor David Bull</title>
  <meta name="Generator" content="Cocoa HTML Writer">
  <meta name="CocoaVersion" content="2022.2">
  <style type="text/css">
    body {background-color: #d5d5d5}
    p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 12.0px 'Helvetica Light'; color: #1a1a1a; -webkit-text-stroke: #1a1a1a; min-height: 14.0px}
    p.p2 {margin: 0.0px 0.0px 1.0px 0.0px; text-align: center; font: 12.0px 'Helvetica Light'; color: #1a1a1a; -webkit-text-stroke: #1a1a1a}
    p.p4 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 14.0px Helvetica; color: #1a1a1a; -webkit-text-stroke: #1a1a1a}
    p.p5 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 12.0px 'Helvetica Light'; color: #1a1a1a; -webkit-text-stroke: #1a1a1a}
    p.p7 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Helvetica Light'; color: #1a1a1a; -webkit-text-stroke: #1a1a1a; min-height: 14.0px}
    p.p8 {margin: 0.0px 0.0px 12.0px 0.0px; font: 12.0px Helvetica; color: #000099; -webkit-text-stroke: #000099}
    p.p10 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; color: #000099; -webkit-text-stroke: #000099}
    p.p11 {margin: 0.0px 0.0px 6.0px 0.0px; font: 12.0px 'Helvetica Light'; color: #1a1a1a; -webkit-text-stroke: #1a1a1a; min-height: 14.0px}
    p.p15 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Helvetica; color: #000099; -webkit-text-stroke: #000099}
    p.p16 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; color: #000099; -webkit-text-stroke: #000099; background-color: #ffffff}
    p.p17 {margin: 0.0px 0.0px 12.0px 0.0px; font: 12.0px 'Helvetica Light'; color: #1a1a1a; -webkit-text-stroke: #1a1a1a}
    p.p19 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Helvetica; color: #1a1a1a; -webkit-text-stroke: #1a1a1a; background-color: #ffffff}
    li.li6 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 12.0px 'Helvetica Light'; color: #1a1a1a; min-height: 14.0px}
    li.li12 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Helvetica; color: #1a1a1a; -webkit-text-stroke: #1a1a1a}
    li.li13 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Helvetica Light'; color: #1a1a1a; -webkit-text-stroke: #1a1a1a}
    li.li14 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Helvetica Light'; color: #1a1a1a}
    span.s1 {font-kerning: none}
    span.s2 {font-kerning: none; background-color: #ffffff}
    span.s3 {font: 12.0px Helvetica; font-kerning: none; color: #000099; -webkit-text-stroke: 0px #000099}
    span.s4 {font: 12.0px 'Helvetica Light'; font-kerning: none; color: #1a1a1a; background-color: #ffffff; -webkit-text-stroke: 0px #1a1a1a}
    span.s5 {font: 12.0px Helvetica; text-decoration: underline ; font-kerning: none; color: #000099; -webkit-text-stroke: 0px #000099}
    span.s6 {background-color: #ffffff; -webkit-text-stroke: 0px #000000}
    span.s7 {font: 14.0px Helvetica; background-color: #ffffff; -webkit-text-stroke: 0px #000000}
    span.s8 {font: 14.0px Helvetica; font-kerning: none; background-color: #ffffff}
    span.s9 {text-decoration: underline ; font-kerning: none; background-color: #ffffff}
    span.s10 {text-decoration: underline ; font-kerning: none}
    span.s11 {font: 12.0px Helvetica; color: #000099; background-color: #ffffff; -webkit-text-stroke: 0px #000000}
    span.s12 {text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #000099}
    ol.ol1 {list-style-type: decimal}
    ul.ul1 {list-style-type: none}
    ul.ul2 {list-style-type: disc}
    ul.ul3 {list-style-type: circle}
  </style>
</head>
<body>
<p class="p1"><span class="s1"></span><br></p>
<p class="p1"><span class="s1"></span><br></p>
<p class="p2"><span class="s1"><img src="file:///Fan.jpg" alt="Fan.jpg"></span></p>
<p class="p1"><span class="s1"></span><br></p>
<p class="p1"><span class="s1"></span><br></p>
<h1 style="margin: 0.0px 0.0px 20.0px 0.0px; text-align: center; font: 24.0px Helvetica; color: #262626; -webkit-text-stroke: #262626"><span class="s2"><b>David Bull</b></span></h1>
<p class="p4"><span class="s2"><b>Professor</b></span></p>
<p class="p5"><span class="s2">in Image and Video Communication</span></p>
<p class="p1"><span class="s1"></span><br></p>
<p class="p5"><span class="s2">1.23, 1 Cathedral Square</span></p>
<p class="p5"><span class="s2">University of Bristol</span></p>
<p class="p5"><span class="s2">Bristol BS1 5DD, United Kingdom</span></p>
<p class="p5"><span class="s2">fan.zhang@bristol.ac.uk</span></p>
<ul class="ul1">
  <li class="li6"></li>
</ul>
<p class="p7"><span class="s1"></span><br></p>
<p class="p7"><span class="s1"></span><br></p>
<p class="p7"><span class="s1"></span><br></p>
<p class="p8"><span class="s1"><a href="https://www.bristol.ac.uk/"><object data="file:///uob-logo.svg">uob-logo.svg</object><span class="s3"></span></a></span></p>
<p class="p8"><span class="s1"><a href="https://www.bristol.ac.uk/vision-institute"><img src="file:///bvilogo.png" alt="bvilogo.png"><span class="s3"></span></a></span></p>
<p class="p8"><span class="s1"><a href="https://vilab.blogs.bristol.ac.uk/"><img src="file:///VILogo.jpg" alt="VILogo.jpg"><span class="s3"></span></a></span></p>
<p class="p7"><span class="s1"></span><br></p>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; font: 18.0px 'Helvetica Light'; color: #434343; -webkit-text-stroke: #434343"><span class="s2">About</span></h2>
<p class="p10"><span class="s4">I am currently working as a Research Fellow in the <a href="http://www.bristol.ac.uk/vi-lab/"><span class="s5">Visual Information Laboratory</span></a>, which is led by <a href="http://www.bristol.ac.uk/eeng/department/staff/drb.html"><span class="s5">Prof. David Bull</span></a>, within the <a href="http://www.bris.ac.uk/eeng/"><span class="s5">Department of Electrical and Electronic Engineering</span></a>, <a href="http://www.bris.ac.uk/"><span class="s5">University of Bristol</span></a>.<span class="Apple-converted-space"> </span></span></p>
<p class="p11"><span class="s1"></span><br></p>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; font: 18.0px 'Helvetica Light'; color: #434343; -webkit-text-stroke: #434343"><span class="s2">Research Areas</span></h2>
<ul class="ul2">
  <li class="li12"><span class="s6"><b></b></span><span class="s2"><b>Deep Video Coding</b></span></li>
  <ul class="ul3">
    <li class="li13"><span class="s6"></span><span class="s2">AI-enhanced deep video compression</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">New CNN architectures for compression and perceptual loss functions</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">New training methods and databases</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">Reduced complexity architectures</span></li>
  </ul>
</ul>
<ul class="ul2">
  <li class="li12"><span class="s6"><b></b></span><span class="s2"><b>Creative Technology</b></span></li>
  <ul class="ul3">
    <li class="li13"><span class="s6"></span><span class="s2">Video production workflows</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">Immersive (HDR/HFR/HSR/360°/volumetric) video coding and quality assessment</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">New training methods and databases</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">Reduced complexity architectures</span></li>
  </ul>
</ul>
<ul class="ul2">
  <li class="li12"><span class="s6"><b></b></span><span class="s2"><b>Video Quality Assessment</b></span></li>
  <ul class="ul3">
    <li class="li13"><span class="s6"></span><span class="s2">Full reference/reduce reference quality metrics</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">Machine learning based quality metrics</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">HVS property characterisation and subjective quality assessment</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">Crowd-sourced subjective testing</span></li>
  </ul>
</ul>
<ul class="ul2">
  <li class="li12"><span class="s6"><b></b></span><span class="s2"><b>Perceptual Video Coding</b></span></li>
  <ul class="ul3">
    <li class="li13"><span class="s6"></span><span class="s2">Content-aware compression</span></li>
    <li class="li13"><span class="s6"></span><span class="s2">Rate quality optimisation and adaptive RDO/quantisation</span></li>
    <li class="li14"></li>
    <li class="li14"></li>
  </ul>
</ul>
<p class="p11"><span class="s1"></span><br></p>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; font: 18.0px 'Helvetica Light'; color: #434343; -webkit-text-stroke: #434343"><span class="s2">News &amp; Activities</span></h2>
<ul class="ul2">
  <li class="li13"><span class="s7"><b></b></span><span class="s8"><b>Jan 2021:</b></span><span class="s2"> Our paper on <a href="https://arxiv.org/abs/2009.07583"><span class="s5">"Video Compression with CNN-based Post Processing"</span></a> has been accepted by the IEEE MultiMedia Magazine.</span></li>
  <li class="li13"><span class="s7"><b></b></span><span class="s8"><b>Dec 2020:</b></span><span class="s2"> I join the editorial board of <a href="https://ieee-cas.org/publications/transactions-circuits-and-systems-video-technology"><span class="s5">IEEE T-CSVT </span></a>as an associate editor (2021-2022).</span></li>
  <li class="li13"><span class="s7"><b></b></span><span class="s8"><b>Nov 2020:</b></span><span class="s2"> Our paper on <a href="https://arxiv.org/abs/2007.07099"><span class="s5">"MFRNet: A New CNN Architecture for Post-Processing and In-loop Filtering"</span></a> has been accepted by the IEEE Journal of Selected Topics in Singal Processing <a href="https://signalprocessingsociety.org/blog/ieee-jstsp-special-issue-deep-learning-imagevideo-restoration-and-compression"><span class="s5">Special Issue</span></a> on Deep Learning for Image/Video Restoration and Compression.</span></li>
  <li class="li13"><span class="s7"><b></b></span><span class="s8"><b>Apr 2020:</b></span><span class="s2"> We have released a large video database, <a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/BVI-DVC/index.htm"><span class="s5">BVI-DVC</span></a>, for training deep learning based video coding algorithms. It has been identified by <a href="https://jvet-experts.org/doc_end_user/current_document.php?id=10484"><span class="s5">MPEG JVET AHG11</span></a> (neural network-based video coding) as one of their training datasets.</span></li>
  <li class="li13"><span class="s7"><b></b></span><span class="s8"><b>Jan 2020:</b></span><span class="s2"> Organising committee (Finance) <a href="https://pcs2021.org/"><span class="s5">PCS 2021</span></a></span></li>
</ul>
<p class="p15"><span class="s9"><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/news.htm">[All news and activities]</a></span><span class="s4"><span class="Apple-converted-space"> </span></span></p>
<p class="p11"><span class="s1"></span><br></p>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; font: 18.0px 'Helvetica Light'; color: #434343; -webkit-text-stroke: #434343"><span class="s2">Recent Research Projects</span></h2>
<p class="p16"><span class="s10"><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/CNN-PP/">Video Compression with CNN-based Post Processing</a></span></p>
<p class="p17"><span class="s2">This is a new CNN-based post-processing approach, which has been integrated with two state-of-the-art coding standards, VVC and AV1. It offers consistent coding gains on all tested sequences at various spatial resolutions, with average bit rate savings of 4.0% and 5.8% against original VVC and AV1 respectively (based on the assessment of PSNR). This network has also been trained with perceptually inspired loss functions, swhich have further improved reconstruction quality based on perceptual quality assessment (VMAF), with average coding gains of 13.9% over VVC and 10.5% against AV1.</span></p>
<p class="p7"><span class="s1"></span><br></p>
<p class="p16"><span class="s10"><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/Drone/">A Simulation Environment for Drone Cinematography</a></span></p>
<p class="p17"><span class="s2">A workflow has been developed for the simulation of drone operations exploiting realistic background environments constructed within Unreal Engine 4 (UE4). This simulation tool will contribute to enhanced productivity, improved safety (awareness and mitigations for crowds and buildings), improved confidence of operators and directors and ultimately enhanced quality of viewer experience.</span></p>
<p class="p7"><span class="s1"></span><br></p>
<p class="p16"><span class="s10"><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/ViSTRA/">ViSTRA: Video Compression based on Resolution Adaptation</a></span></p>
<p class="p17"><span class="s2">ViSTRA a new video compression framework which exploits adaptation of spatial/temporal resolution and effective bit depth, down-sampling these parameters at the encoder based on perceptual criteria, and up-sampling at the decoder using a deep convolution neural network.</span></p>
<p class="p7"><span class="s1"></span><br></p>
<p class="p15"><span class="s9"><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/research.htm">[All research projects]</a></span><span class="s4"><span class="Apple-converted-space"> </span></span></p>
<h3 style="margin: 0.0px 0.0px 14.0px 0.0px; font: 14.0px Helvetica; color: #1a1a1a; -webkit-text-stroke: #1a1a1a; min-height: 17.0px"><span class="s1"><b></b></span><br></h3>
<p class="p11"><span class="s1"></span><br></p>
<h2 style="margin: 0.0px 0.0px 14.9px 0.0px; font: 18.0px 'Helvetica Light'; color: #434343; -webkit-text-stroke: #434343"><span class="s2">Publication</span></h2>
<p class="p19"><span class="s1"><b>Book and Book Chapters</b></span></p>
<ol class="ol1">
  <li class="li13"><span class="s6"></span><span class="s2">Intelligent Image and Video Compression: Communicating Pictures. <a href="https://www.amazon.co.uk/Image-Video-Compression-Communicating-Pictures/dp/0128203536/"><span class="s5">[book]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/Intelligent-Image-and-Video-Compression.htm"><span class="s5">[software]</span></a> </span><span class="s1"><br>
</span><span class="s2">D. Bull and F. Zhang, <i>2nd Edition</i>, Oxford: Academic Press, in Press. </span><span class="s1"><br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Measuring video quality. <a href="http://www.sciencedirect.com/science/article/pii/B9780124201491000077"><span class="s5">[book]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang and D. Bull, <i>In: Sergios Theodoridis and Rama Chellappa, editors, Academic Press Library in Signal Processing. Vol 5. </i>, Oxford: Academic Press, 2014, pp 227-249. ISBN: 978-0-12-420149-1. </span><span class="s1"><br>
</span></li>
</ol>
<p class="p19"><span class="s1"><b>MPEG Standard Contributions</b></span></p>
<ol class="ol1">
  <li class="li13"><span class="s11"><a href="http://phenix.it-sudparis.eu/jvet/doc_end_user/current_document.php?id=3432"><span class="s12">Description of SDR video coding technology proposal by University of Bristol (JVET-J0031)</span></a></span><span class="s2"> </span><span class="s1"><br>
</span><span class="s2">D. Bull, F. Zhang and M. Afonso, <i>A submission to the Joint Call for Proposals on Video Compression with Capability beyond HEVC,</i> April 2018 in San Diego. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s11"><a href="http://phenix.int-evry.fr/jct/doc_end_user/current_document.php?id=10306"><span class="s12">BVI_Texture UHD 120fps test sequences for HEVC and beyond (JCTVC-V0099)</span></a></span><span class="s2"> </span><span class="s1"><br>
</span><span class="s2">M. Papadopoulos, F. Zhang, D. Agrafiotis, D. Bull and J.-R. Ohm, October 2015 in Geneva. </span><span class="s1"><br>
<br>
</span></li>
</ol>
<p class="p19"><span class="s1"><b>arXiv Papers</b></span></p>
<ol class="ol1">
  <li class="li13"><span class="s6"></span><span class="s2">CVEGAN: a perceptually-inspired GAN for compressed video enhancement. <a href="https://arxiv.org/abs/2011.09190"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">D. Ma, F. Zhang, and D. R. Bull, arXiv:2011.09190, 2020 </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">BVI-DVC: A Training Database for Deep Video Compression. <a href="https://arxiv.org/abs/2003.13552"><span class="s5">[paper]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/BVI-DVC/index.htm"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">D. Ma, F. Zhang, and D. R. Bull, arXiv:2003.13552, 2020 </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Comparing VVC, HEVC and AV1 using Objective and Subjective Assessments. <a href="https://arxiv.org/abs/2003.10282"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?p=2295"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang, A. V. Katsenou, M. Afonso, G. Dimitrov and D. R. Bull, arXiv:2003. 10282, 2020. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">ViSTRA2: Video Coding using Spatial Resolution and Effective Bit Depth Adaptation. <a href="https://arxiv.org/abs/1911.02833"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.bristol.ac.uk/?p=2278"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang, M. Afonso and D. R. Bull, arXiv:1911.02833, 2019 </span><span class="s1"><br>
</span></li>
</ol>
<p class="p19"><span class="s1"><b>Journal Papers</b></span></p>
<ol class="ol1">
  <li class="li13"><span class="s6"></span><span class="s2">Video Compression with CNN-based Post Processing. <a href="https://arxiv.org/abs/2009.07583"><span class="s5">[paper]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/CNN-PP/index.htm"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang, D. Ma, C. Feng and D. R. Bull, <i>IEEE MultiMedia Magazine</i>, accepted. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">MFRNet: A New CNN Architecture for Post-Processing and In-loop Filtering. <a href="https://arxiv.org/abs/2007.07099"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">D. Ma, F. Zhang, and D. R. Bull, <i>IEEE Journal of Selected Topics in Singal Processing</i>, accepted. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Study of High Frame Rate Video Formats. <a href="https://ieeexplore.ieee.org/document/8531714"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?p=1563"><span class="s5">[project]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/BVI-DVC/index.htm"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">A. Mackin, F. Zhang, and D. R. Bull, <i>IEEE T-MM,</i> 2019. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Video Compression based on Spatio-Temporal Resolution Adaptation. <a href="https://ieeexplore.ieee.org/document/8517114"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.bristol.ac.uk/?p=2278"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">M. Afonso, F. Zhang and D. R. Bull, <i>IEEE T-CSVT (Letter),</i> 2019. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Rate-distortion Optimization Using Adaptive Lagrange Multipliers. <a href="https://ieeexplore.ieee.org/document/8482327"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?p=2268"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang and D. R. Bull, <i>IEEE T-CSVT,</i> 2019. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">BVI-HD: A Video Quality Database for HEVC Compressed and Texture Synthesised Content. <a href="https://ieeexplore.ieee.org/document/8322297"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?p=1946"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang, F. Mercer Moss, R. Baddeley and D. R. Bull, <i>IEEE T-MM,</i> 2018. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Reduced-Reference Video Quality Metric Using Spatial Information in Salient Regions. <a href="http://journal.uad.ac.id/index.php/TELKOMNIKA/article/view/9036/pdf_679"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. D. A. Rahman, D. Agrafiotis, O. O. Khalifa and F. Zhang, <i>TELKOMNIKA (Telecommunication Computing Electronics and Control),</i> 2018. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">On the Optimal Presentation Duration for Subjective Video Quality Assessment. <a href="https://ieeexplore.ieee.org/document/7172512"><span class="s5">[dataset]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/Duration/index.htm"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Mercer Moss, K. Wang, F. Zhang, R. Baddeley and D. Bull, <i>IEEE T-CSVT,</i> November 2016. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Support for Reduced Presentation Durations in Subjective Video Quality Assessment. <a href="http://www.sciencedirect.com/science/article/pii/S0923596516301126"><span class="s5">[paper]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/Duration/index.htm"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Mercer Moss, C.-T. Yeh, F. Zhang, R. Baddeley, D. R. Bull, <i>Elsevier Signal Processing: Image Communication,</i> October 2016. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Perception-based Hybrid Model for Video Quality Assessment <a href="https://ieeexplore.ieee.org/document/7100892"><span class="s5">[paper]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/VQA/PVM_code.zip"><span class="s5">[code]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/VQA/index.htm"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang and D. Bull, <i>IEEE T-CSVT,</i> June 2016. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Perception-oriented Video Coding based on Image Analysis and Completion: a Review. <a href="http://www.sciencedirect.com/science/article/pii/S0923596512000100"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">P. Ndjiki-Nya, D. Doshkov, H. Kaprykowsky, F. Zhang, D. Bull, T. Wiegand, <i>Signal Processing: Image Communication</i>, July 2012. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Parametric Framework For Video Compression Using Region-based Texture Models. <a href="https://ieeexplore.ieee.org/document/5986673"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?page_id=553"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang and D. Bull, <i>IEEE J-STSP</i>, November 2011. </span><span class="s1"><br>
</span></li>
</ol>
<p class="p19"><span class="s1"><b>Conference Contributions</b></span></p>
<ol class="ol1">
  <li class="li13"><span class="s6"></span><span class="s2">Enhancing VVC through CNN-based Post-Processing. <a href="https://ieeexplore.ieee.org/document/9102912"><span class="s5">[paper]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/CNN-PP/index.htm"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang, C. Feng and D. Bull, <i>ICME,</i> 2020. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Simulation Environment for Drone Cinematography. <a href="https://www.ibc.org/technical-papers/a-simulation-environment-for-drone-cinematography/6747.article"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang, D. Hall, T. Xu, S. Boyle and D. Bull, <i>IBC,</i> 2020. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Video compression with low complexity CNN-based spatial resolution adaptation. <a href="https://arxiv.org/abs/2007.14726"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">D. Ma, F. Zhang, and D. Bull, <i>SPIE,</i> 2020. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">GAN-based Effective Bit Depth Adaptation for Perceptual Video Compression. <a href="https://ieeexplore.ieee.org/document/9102865"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">D. Ma, F. Zhang and D. Bull, <i>ICME,</i> 2020. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Encoding in the Dark Grand Challenge: An Overview. <a href="https://ieeexplore.ieee.org/document/9106011"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">N. Anantrasirichai, F. Zhang, A. Malyugina, P. Hill, A. Katsenou, <i>ICME Workshops,</i> 2020. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Enhanced Video Compression based on Effective Bit Depth Adaptation. <a href="https://ieeexplore.ieee.org/document/8803185"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang, M. Afonso and D. Bull, <i>ICIP,</i> 2019. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Subjective Study of Viewing Experience for Drone VIdeos Using Simulated Content. <a href="https://ieeexplore.ieee.org/document/8803747"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">S. Boyle, F. Zhang and D. Bull, <i>ICIP,</i> 2019. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Subjective Comparison of AV1 and HEVC for Adaptive Video Streaming. <a href="https://ieeexplore.ieee.org/document/8803523"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?p=2295"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">A. Katsenou, F. Zhang, M. Afonso and D. Bull, <i>ICIP,</i> 2019. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Frame Rate Conversion Method based on a Virtual Shutter Angle. <a href="https://ieeexplore.ieee.org/document/8803489"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">A. Mackin, F. Zhang and D. Bull, <i>ICIP,</i> 2019. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Environment Capture and Simulation for UAV Cinematography Planning and Training. <a href="http://eusipco2019.org/wp-content/uploads/2019/08/Environment_Capture_and_Simulation_for_UAV_Cinematography_Planning_and_Training.pdf"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">S. Boyle, M. Newton, F. Zhang and D. Bull, <i>EUSIPCO,</i> 2019. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Perceptually-inspired Super-resolution of Compressed Videos. <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11137/1113717/Perceptually-inspired-super-resolution-of-compressed-videos/10.1117/12.2530688.short"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">D. Ma, M. Afonso, F. Zhang and D. Bull, <i>SPIE,</i> 2019. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">The Future of Media Production Through Multi-drones' Eyes. <a href="https://personal.us.es/jcapitan/preprint/messina_ibc18_web.pdf"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">A. Messina, S. Metta, M. Montagnuolo, F. Negro, V. Mygdalis, I. Pitas, J. Capitan, A. Torres, S. Boyle, D. Bull and F. Zhang, <i>IBC,</i> 2018. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A study of subjective video quality at various spatial resolutions. <a href="https://ieeexplore.ieee.org/document/8451225"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.bristol.ac.uk/?p=2391"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">A. Mackin, M. Afonso, F. Zhang and D. Bull, <i>ICIP,</i> 2018. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Spatial resolution adaptation framework for video compression. <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10752/107520L/Spatial-resolution-adaptation-framework-for-video-compression/10.1117/12.2320520.short?SSO=1"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">M. Afonso, F. Zhang and D. Bull, <i>SPIE,</i> 2018. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">SRQM: A Video Quality Metric for Spatial Resolution Adaptation. <a href="https://ieeexplore.ieee.org/document/8456246"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.bristol.ac.uk/?p=2180"><span class="s5">[code]</span></a> </span><span class="s1"><br>
</span><span class="s2">A. Mackin, M. Afonso, F. Zhang and D. Bull, <i>PCS,</i> 2018. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Frame Rate Dependent Video Quality Metric based on Temporal Wavelet Decomposition and Spatiotemporal Pooling. <a href="http://ieeexplore.ieee.org/document/8296291"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.bristol.ac.uk/?p=2265%22"><span class="s5">[code]</span></a> </span><span class="s1"><br>
</span><span class="s2">F Zhang, A Mackin and D. R. Bull, <i>ICIP,</i> 2017. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Low Complexity Video Coding Based on Spatial Resolution Adaptation. <a href="http://ieeexplore.ieee.org/document/8296835"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">M. Afonso, F. Zhang, A. Katsenou, D. Agrafiotis, D. Bull, <i>ICIP,</i> 2017. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Investigating the Impact of High Frame Rates on Video Compression. <a href="https://ieeexplore.ieee.org/document/8296290"><span class="s5">[paper]</span></a><a href="https://data.bris.ac.uk/data/dataset/k8bfn0qsj9fs1rwnc2x75z6t7"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">A. Mackin, F. Zhang, M. A. Papadopoulos, D. Bull, <i>ICIP,</i> 2017. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Video Texture Analysis based on HEVC Encoding Statistics. <a href="https://ieeexplore.ieee.org/document/7906312"><span class="s5">[paper]</span></a><a href="https://data.bris.ac.uk/data/dataset/1h2kpxmxdhccf1gbi2pmvga6qp"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">M. Afonso, A. Katsenou, F. Zhang, D. Agrafiotis, D. Bull, <i>PCS,</i> 2016. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">HEVC Enhancement using Content-based Local QP Selection. <a href="https://ieeexplore.ieee.org/document/7533154"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang and D. Bull, <i>ICIP,</i> 2016. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">An Adaptive QP Offset Determination Method for HEVC. <a href="https://ieeexplore.ieee.org/document/7533155"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">M. A. Papadopoulos, F. Zhang, D. Agrafiotis, D. R. Bull, <i>ICIP,</i> 2016. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">What's on TV: A Large Scale Quantitative Characterisation of Modern Broadcast Video Content. <a href="https://ieeexplore.ieee.org/document/7532794"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?p=1554"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Mercer Moss, F. Zhang, R. Baddeley, D. R. Bull, <i>ICIP,</i> 2016. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">An Adaptive Lagrange Multiplier Determination Method for Rate-distortion Optimisation in Hybrid Video Codecs. <a href="https://ieeexplore.ieee.org/document/7350883"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?p=2268"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang and D. Bull, <i>ICIP,</i> 2015. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Study of Subjective Video Quality at Various Frame Rates. <a href="https://ieeexplore.ieee.org/document/7351436"><span class="s5">[paper]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/BVI-HFR/index.htm"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">A. Mackin, F. Zhang and D. Bull, <i>ICIP,</i> 2015. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Very Low Complextiy Reduced Reference Video Quality Metric based on Spatio-temporal Information Selection. <a href="https://ieeexplore.ieee.org/document/7350863"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">M. Wang, F. Zhang and D. Agrafiotis, <i>ICIP,</i> 2015. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">A Video Texture Database for Perceptual Compression and Quality Assessment. <a href="https://ieeexplore.ieee.org/document/7351309"><span class="s5">[paper]</span></a><a href="https://data.bris.ac.uk/datasets/1if54ya4xpph81fbo1gkpk5kk4/"><span class="s5">[dataset]</span></a> </span><span class="s1"><br>
</span><span class="s2">M. A. Papadopoulos, F. Zhang, D.Agrafiotis and D. Bull, <i>ICIP,</i> 2015. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Optimal sequence duration for subjective video quality assessment. <a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=2444238"><span class="s5">[paper]</span></a><a href="file:///Users/eedrb/Documents/Admin/research/VI-Lab/Website/db%20github/fan-aaron-zhang.github.io%5B1%5D/Duration/index.htm"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. J. Mercer Moss, K. Wang, F. Zhang, R. Baddeley and D. Bull, <i>SPIE Optical Engineering+ Applications,</i> 2015. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Quality Assessment Methods for Perceptual Video Compression. <a href="https://ieeexplore.ieee.org/document/6738009"><span class="s5">[paper]</span></a><a href="http://vilab.blogs.ilrt.org/files/2016/06/PVM_code.zip"><span class="s5">[code]</span></a><a href="https://vilab.blogs.ilrt.org/?p=787"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang and D. Bull, <i>ICIP,</i> Melbourne, Australia, September 2013. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Production of high dynamic range video. <a href="http://www.bbc.co.uk/rd/publications/whitepaper269"><span class="s5">[paper]</span></a> </span><span class="s1"><br>
</span><span class="s2">M. Price, D. Bull, T. Flaxton, S. Hinde, R. Salmon, A. Sheikh, G. Thomas, and F. Zhang, <i>IBC</i>, Amsterdam, September, 2013. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Advances in Region-based Texture Modeling for Video Compression. <a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1267237"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?page_id=553"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang and D. Bull, <i>Proc. SPIE 8135</i>, San Diego, USA, August, 2011. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Enhanced Video Compression With Region-Based Texture Models. <a href="https://ieeexplore.ieee.org/document/5702560"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?page_id=553"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang and D. Bull, <i>PCS</i>, Nagoya, Japan, December, 2010. </span><span class="s1"><br>
<br>
</span></li>
  <li class="li13"><span class="s6"></span><span class="s2">Region-Based Texture Modelling For Next Generation Video Codecs <a href="https://ieeexplore.ieee.org/document/5651626"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?page_id=553"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">F. Zhang, D. Bull, and N. Canagarajah, <i>ICIP</i>, Hong Kong, China, September, 2010. </span><span class="s1"><br>
</span></li>
</ol>
<p class="p7"><span class="s1"></span><br></p>
<p class="p19"><span class="s1"><b>Other Publications</b></span></p>
<ol class="ol1">
  <li class="li13"><span class="s6"></span><span class="s2">Exploring the Challenges of Higher Frame Rates: from Quality Assessment to Frame Rate Selection. <a href="http://mmc.committees.comsoc.org/files/2018/07/01-MMTC_Communication_Frontier_May_2018-Final-Revised.pdf"><span class="s5">[paper]</span></a><a href="https://vilab.blogs.ilrt.org/?p=1563"><span class="s5">[project]</span></a> </span><span class="s1"><br>
</span><span class="s2">A. V. Katsenou, A. Mackin, D. Ma, F. Zhang and D. R. Bull, <i>IEEE COMSOC MMTC Communications - Frontiers (E-Letter),</i> May 2018 (invited). </span><span class="s1"><br>
<br>
</span></li>
</ol>
<p class="p10"><span class="s1"><a href="http://statcounter.com/"><span class="s3"></span></a></span></p>
<p class="p11"><span class="s1"></span><br></p>
</body>
</html>
